<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="blog cools  https://nlpprogress.com/ https://www.ruder.io/ https://peltarion.com/blog/topic/nlp article cool https://arxiv.org/pdf/2204.14264.pdf jsp https://medium.com/dair-ai/relaunching-the-nlp-newsletter-1bd91106c7da https://thegradient.pub/ https://thegradient.pub/prompting/
difficulties  Language distribution / limited Data / curse of multilinguality Homogeneity / Lack of pre-training data Over-representation of Western concepts Translation / Quality issues Multilingual evaluation Dependence on retrieval : It assumes there is a single gold paragraph providing the correct answer and does not consider information from other paragraphs or pages."><title>ü™¥ Quartz 3.2</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://quartz.jzhao.xyz//icon.png><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Source+Sans+Pro:wght@400;600;700&family=Fira+Code:wght@400;700&display=swap" rel=stylesheet><link href=https://quartz.jzhao.xyz/styles.8010c0d8fb32a34f00886b05df3d230c.min.css rel=stylesheet><script src=https://quartz.jzhao.xyz/js/darkmode.46b07878b7f5d9e26ad7a3c40f8a0605.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script src=https://quartz.jzhao.xyz/js/popover.688c5dcb89a57776d7f1cbeaf6f7c44b.min.js></script>
<script>const BASE_URL="https://quartz.jzhao.xyz/",fetchData=Promise.all([fetch("https://quartz.jzhao.xyz/indices/linkIndex.1792bced5c70957691d733bec9f38087.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://quartz.jzhao.xyz/indices/contentIndex.0520961e9a4d49e31703c989f88a3c5e.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const n=new URL("https://quartz.jzhao.xyz/"),s=n.pathname,o=window.location.pathname,i=s==o,e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=i&&!1;drawGraph("https://quartz.jzhao.xyz",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2}),initPopover("https://quartz.jzhao.xyz",!0,!0)},init=(e=document)=>{renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/quartz.jzhao.xyz\/js\/router.557a499829be51f9008c6efa5b73602a.min.js"
    attachSPARouting(init, render)
  </script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-XYFD95KB4J"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XYFD95KB4J",{anonymize_ip:!1})}</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://quartz.jzhao.xyz/js/search.cf33b507388f3dfd5513a2afcda7af41.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://quartz.jzhao.xyz/>ü™¥ Quartz 3.2</a></h1><svg tabindex="0" id="search-icon" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg><div class=spacer></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><p class=meta>Last updated February 5, 2023</p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><ol><li><a href=#blog-cools>blog cools</a></li></ol></li><li><a href=#difficulties>difficulties</a></li><li><a href=#citations>Citations</a></li></ol><ol><li><ol><li><a href=#multitask-multilang-benchmarks->Multitask multilang benchmarks :</a></li><li><a href=#mono-task--mono-lang-benchmarks->mono task / mono lang benchmarks :</a></li></ol></li><li><a href=#models>Models</a></li><li><a href=#byt5--300m-129b>ByT5 | 300M-12.9B</a></li><li><a href=#turing-ulr-xlm-e--279m-22b>Turing ULR (XLM-E) | 279M-2.2B</a></li><li><a href=#vega>Vega</a></li><li><a href=#polyglot>Polyglot</a></li><li><a href=#mt5--mt0--300m---13b>MT5 / MT0 | 300m - 13B¬†</a></li><li><a href=#mbert--180b>MBERT | 180B¬†</a></li><li><a href=#bloom--blommz-176b>Bloom | Blommz 176B¬†</a></li></ol><ol><li><a href=#canine>CANINE</a></li><li><a href=#perceiver-and-perceiver-io>Perceiver and Perceiver IO</a></li><li><a href=#charformer>Charformer</a></li><li><a href=#articles>Articles</a><ol><li><a href=#state-of-art>State of art</a></li><li><a href=#multitask>Multitask</a></li><li><a href=#mulitlang>Mulitlang</a></li></ol></li><li><a href=#paper>Paper</a><ol><li><a href=#datasets>Datasets</a></li><li><a href=#qa>QA</a></li><li><a href=#multitask-1>Multitask</a></li><li><a href=#multilang>Multilang</a></li><li><a href=#zero-shot-learning>Zero shot learning</a></li></ol></li><li><a href=#others>Others</a><ol><li><a href=#multimodal>multimodal</a></li><li><a href=#cool-link>Cool link</a></li><li><a href=#archive>archive</a></li></ol></li></ol></nav></details></aside><a href=#blog-cools><h3 id=blog-cools><span class=hanchor arialabel=Anchor># </span>blog cools</h3></a><p><a href=https://nlpprogress.com/ rel=noopener>https://nlpprogress.com/</a>
<a href=https://www.ruder.io/ rel=noopener>https://www.ruder.io/</a>
<a href=https://peltarion.com/blog/topic/nlp rel=noopener>https://peltarion.com/blog/topic/nlp</a>
article cool
<a href=https://arxiv.org/pdf/2204.14264.pdf rel=noopener>https://arxiv.org/pdf/2204.14264.pdf</a>
jsp
<a href=https://medium.com/dair-ai/relaunching-the-nlp-newsletter-1bd91106c7da rel=noopener>https://medium.com/dair-ai/relaunching-the-nlp-newsletter-1bd91106c7da</a>
<a href=https://thegradient.pub/ rel=noopener>https://thegradient.pub/</a>
<a href=https://thegradient.pub/prompting/ rel=noopener>https://thegradient.pub/prompting/</a></p><a href=#difficulties><h2 id=difficulties><span class=hanchor arialabel=Anchor># </span>difficulties</h2></a><ul><li>Language distribution / limited Data / curse of multilinguality</li><li>Homogeneity / Lack of pre-training data</li><li>Over-representation of Western concepts</li><li>Translation / Quality issues</li><li>Multilingual evaluation</li><li>Dependence on retrieval : It assumes there is a single gold paragraph providing the correct answer and does not consider information from other paragraphs or pages.</li></ul><a href=#citations><h2 id=citations><span class=hanchor arialabel=Anchor># </span>Citations</h2></a><p>A number of factors has been found to be important for learning robust multilingual representations, including <strong>shared tokens</strong>, <strong>subword fertility</strong>, and <strong>word embedding alignment</strong>.</p><p><strong>Adapters</strong> have been shown to improve robustness, lead to increased sample efficiency compared to fine-tuning</p><p><strong>tokenization</strong> often produces poor segmentations for languages with a rich morphology or limited data.</p><p>Architeture of models can be adapted to incorporate information about morphology such as in the KinyaBERT model for Kinyarwanda</p><hr><a href=#preprocess><h1 id=preprocess><span class=hanchor arialabel=Anchor># </span>preprocess</h1></a><p><a href=https://github.com/explosion/spaCy/tree/v3.5.0 rel=noopener>https://github.com/explosion/spaCy/tree/v3.5.0</a></p><a href=#benchmarks--normalized-state-of-the-art-performance><h1 id=benchmarks--normalized-state-of-the-art-performance><span class=hanchor arialabel=Anchor># </span>Benchmarks / normalized state-of-the-art performance</h1></a><p><a href=https://tmmtt.medium.com/natural-language-processing-nlp-dc2c1d8d4110 rel=noopener>list of some benchmarks</a></p><a href=#multitask-multilang-benchmarks-><h3 id=multitask-multilang-benchmarks-><span class=hanchor arialabel=Anchor># </span>Multitask multilang benchmarks :</h3></a><p><a href=https://sites.research.google/xtreme rel=noopener>XTREME</a>
<a href=https://gluebenchmark.com/ rel=noopener>GLue / superGlue</a>
XNLI
&ndash;[glge]&ndash;
&ndash;
<a href=https://ai.google.com/research/tydiqa rel=noopener>TyDi QA</a>.&ndash;</p><a href=#mono-task--mono-lang-benchmarks-><h3 id=mono-task--mono-lang-benchmarks-><span class=hanchor arialabel=Anchor># </span>mono task / mono lang benchmarks :</h3></a><p><a href=http://nlpprogress.com/english/dependency_parsing.html rel=noopener>NLP-progress</a>
[Tatoeba]
XNLI, XQuAD, and XCOPA are based on translations of established English datasets.</p><hr><a href=#models><h2 id=models><span class=hanchor arialabel=Anchor># </span>Models</h2></a><a href=#byt5--300m-129b><h2 id=byt5--300m-129b><span class=hanchor arialabel=Anchor># </span>ByT5 | 300M-12.9B</h2></a><p>08/03/2022
<strong>Towards a token-free future with pre-trained byte-to-byte models</strong>
<a href=https://arxiv.org/abs/2105.13626 rel=noopener>https://arxiv.org/abs/2105.13626</a>
the number of encoder layers is 3x more than the decoders.
ByT5 out-performs mT5 in most multilingual tasks, and especially for smaller models or when dealing with misspelled or noisy data, and is 50-100% faster.
<img src="/Pasted image 20230205133314.png" title="/Pasted image 20230205133314.png">
<img src="/Pasted image 20230205123454.png" title="/Pasted image 20230205123454.png"></p><a href=#turing-ulr-xlm-e--279m-22b><h2 id=turing-ulr-xlm-e--279m-22b><span class=hanchor arialabel=Anchor># </span>Turing ULR (XLM-E) | 279M-2.2B</h2></a><p>19/04/2022
#1 at XTREME and GLue benchmark
<a href=https://arxiv.org/abs/2106.16138 rel=noopener>https://arxiv.org/abs/2106.16138</a>
Based on XLM from 2019 in
<a href=https://arxiv.org/abs/1901.07291 rel=noopener>Cross-lingual Language Model Pretraining</a>
and from
<a href="https://openreview.net/forum?id=r1xMH1BtvB" rel=noopener>ELECTRA-style tasks</a> to cross-lingual language model pre-training.</p><p>two transformers encoders :</p><ul><li>G the generator, like Bert, rained with the masked language modeling (MLM)</li><li>D the discriminator, who takes the result of G and determine which token is corrupted.
final loss is L = Lg + ŒªLd
<strong><img src=https://lh4.googleusercontent.com/bvWcnGAW17znGP5dqeSvLMvSMTs1yxfHPtkKuTyeb3nToYhIyQFwF8nAinTv8C3OF_pRCkrnaHDtqhezVcLhmzg1e-ThiJMO2o0h_tQqMKnkj_XvlR6OJV-d7d1uGiitsDqufIsq184Hvvp3jeo0_Mg alt></strong>
<strong><img src=https://lh3.googleusercontent.com/VkqTavnxote5GPaMmCoIQzR6ymruErZ4wtacp8NeENUVppZhNbRujqHT03hOqY1sZEcvS1LHgrC4clBX9mWgnIAZtGYmUaJNgssfzuTfiWhpU46wdNvKBJT-yi71yOq3o5355O5zT8itElRlD7FCgek alt></strong></li></ul><a href=#vega><h2 id=vega><span class=hanchor arialabel=Anchor># </span>Vega</h2></a><p>#1 at SuperGlue
<a href=https://arxiv.org/pdf/2212.01853.pdf rel=noopener>https://arxiv.org/pdf/2212.01853.pdf</a>
self-evolution learning for PLMs to wisely predict the informative tokens that should be masked, and supervise the masked language modeling (MLM) process with rectified smooth labels.
<strong><img src=https://lh6.googleusercontent.com/Fcc1CLwnYKPgeVPFUPFI7nvsq2ZRPR8a5s6L-8Mw84U0X13O7cBluBPUuY6K09mmBmOajjOwLdFJ1DtBg3_ico7wYxlfTxsH3gkrhqu_FjhYYCpRjXlBRb5tUNFhs59-j8HmbvqulUbAtM1-DAcBTVY alt></strong>
<img src=https://lh6.googleusercontent.com/BCsG_YZDuGdgchkQjicwx8OJ_P50vRiNqsDNNo0iYLR1TbYk02Zk3yQ2R1kIKP9DPZiXXhRB8cqEbvLihMfgMn6qqK9nq2JTAsec7qcDcC7uWd023-HbTsT7tAwaANgxSclhMQRWZm8FnFBP-G86zaQ alt></p><a href=#polyglot><h2 id=polyglot><span class=hanchor arialabel=Anchor># </span>Polyglot</h2></a><p>04/12/2022
<a href=https://arxiv.org/abs/2204.14264 rel=noopener>https://arxiv.org/abs/2204.14264</a>
6 tasks, namely topic classification, sentiment classification, named entity recognition, question answering, natural language inference, and summarization, covering 24 datasets and 49 languages
<img src=https://lh3.googleusercontent.com/ZOkS5H_evIN2JT5p8PEkwcjWilWk952uGQ_ym6kD9C6FJvqZNEcfdXCOTjxEW1KunELifW9Mj-933aXZkkDema-ib-i1Mgcvd4Yfz9OsOPDn2Mj1-RwV_nV_wfUKVVHrsRg24Q5nWTU_UCSyDDTIMi8 alt>
[Bloom]</p><a href=#mt5--mt0--300m---13b><h2 id=mt5--mt0--300m---13b><span class=hanchor arialabel=Anchor># </span>MT5 / MT0 | 300m - 13B¬†</h2></a><p>11/03/2021
<a href=https://arxiv.org/abs/2010.11934 rel=noopener>https://arxiv.org/abs/2010.11934</a></p><a href=#mbert--180b><h2 id=mbert--180b><span class=hanchor arialabel=Anchor># </span>MBERT | 180B¬†</h2></a><p>11/03/2021
<a href=https://arxiv.org/abs/2010.11934 rel=noopener>https://arxiv.org/abs/2010.11934</a></p><a href=#bloom--blommz-176b><h2 id=bloom--blommz-176b><span class=hanchor arialabel=Anchor># </span>Bloom | Blommz 176B¬†</h2></a><p>11/12/2022
<a href=https://arxiv.org/abs/2211.05100 rel=noopener>https://arxiv.org/abs/2211.05100</a>
<a href=https://arxiv.org/abs/2211.01786 rel=noopener>https://arxiv.org/abs/2211.01786</a></p><a href=#token-free-models><h1 id=token-free-models><span class=hanchor arialabel=Anchor># </span>Token free models</h1></a><a href=#canine><h2 id=canine><span class=hanchor arialabel=Anchor># </span>CANINE</h2></a><p>CANINE is the first token- and vocabulary-free model, based on a hashing and downsampling strategy to work directly on the characters as Unicode code points.
He was trained on the TyDI QA dataset and outperformed other multilingual models, such as mBERT while having no predefined tokenization and 28% fewer parameters.</p><a href=#perceiver-and-perceiver-io><h2 id=perceiver-and-perceiver-io><span class=hanchor arialabel=Anchor># </span>Perceiver and Perceiver IO</h2></a><p>The perceiver operates directly on the raw byte representation of the input. This enables the models to operate (more or less) on any type of data, be it text, images, point cloud, audio, etc.
He takes inspiration from the ByT5 paper to operate directly on the raw byte representation (UTF-8 for text) but extends it to multiple modalities.</p><a href=#charformer><h2 id=charformer><span class=hanchor arialabel=Anchor># </span>Charformer</h2></a><p>Charformer consists of two parts: a dynamic, fast, and flexible method to learn subword representations automatically from n-grams and a model that incorporates it. By grouping n-characters together (n-gram) there is an increased opportunity to learn multiple representations of a word that may be more advantageous. Instead of using only one representation of subwords of a single character, the model can select the most informative representation of a word, by weighting multiple representations from the different n-grams. These are then downsampled in groups of 2 with mean pooling to get a sequence with a shorter length.</p><p>This module is called Gradient-Based Subword Tokenization (GBST) and is the token-free module used by the Charformer. Since all components in the module are pre-defined, except for how to weight/score each n-gram representation, this can be done efficiently and quickly. Also, since the scoring is done using the Softmax function it is also differentiable and learnable. This means that better text representations can update on new vocabulary or languages dynamically.</p><p><img src="https://images.prismic.io/peltarionv2/f83f7da0-edb4-4d77-9313-e60bcf6aa110_Charformer+GBST+model.png?auto=compress%2Cformat&rect=0%2C0%2C1951%2C1711&w=1300&h=1140" alt></p><p>Creating an n-gram of characters shortens the length of the text by n. For instance, the text ‚ÄúSuccessfully‚Äù as a 4-gram would be ‚ÄúSucc‚Äù, ‚Äúessf‚Äù, ‚Äúully‚Äù; that is 4 times shorter than the original text. Therefore, these n-grams are mean pooled and repeated X number of times to be the same length again. The pooled and duplicated embedding for ‚Äúsucc‚Äù in the image below would be C4, 1, ‚Äúessf‚Äù C4, 2 , and ‚Äúully‚Äù C4, 3. These are then scored via a weighting and mean pooled to a shorter representation. Since pooling removes the position of tokens, position embeddings are added to the tokens at each pooling step.</p><p>Charformer performs on par or outperforms the regular T5 on multiple English tasks and outperforms both ByT5 and CANINE while being smaller, faster, and with shorter sequences. Unlike CANINE, a model using the GBST, s.a. Charformer is interpretable in how the tokens are represented. Charformer is as of this writing the current State-of-the-Art (SOTA) method when it comes to token-free models. For those interested in learning more about the model, I highly recommend this¬†
<a href="https://www.youtube.com/watch?v=debgj24BAZE" rel=noopener>short and pedagogical video</a>.</p><p>&ndash;
<a href=/ rel=noopener class=internal-link data-src=/>MShenNonG+TDT</a>&ndash;
&ndash;
<a href=/ rel=noopener class=internal-link data-src=/>CoFe</a>&ndash;
[Palm]
<a href=/ rel=noopener class=internal-link data-src=/>Hyper-X: A Unified Hypernetwork for Multi-Task Multilingual Transfer</a>
[CORA]</p><hr><a href=#articles><h2 id=articles><span class=hanchor arialabel=Anchor># </span>Articles</h2></a><p>Adaptaters :
<a href=https://medium.com/dair-ai/adapters-a-compact-and-extensible-transfer-learning-method-for-nlp-6d18c2399f62 rel=noopener>adaptaters</a></p><a href=#state-of-art><h3 id=state-of-art><span class=hanchor arialabel=Anchor># </span>State of art</h3></a><p><a href=https://peltarion.com/blog/data-science/towards-a-token-free-future-in-nlp rel=noopener>token free research</a></p><p><a href=https://peltarion.com/blog/data-science/a-deep-dive-into-multilingual-nlp-models rel=noopener>A deep dive into multilingual NLP models</a>
<a href=https://www.ruder.io/acl2022/ rel=noopener>ACL 2022: Association for computational linguistic</a>
<a href=https://www.ruder.io/state-of-multilingual-ai/ rel=noopener>The State of Multilingual AI</a>
<a href=https://www.ruder.io/nlp-benchmarking/ rel=noopener>Challenges and Opportunities in NLP Benchmarking</a></p><a href=#multitask><h3 id=multitask><span class=hanchor arialabel=Anchor># </span>Multitask</h3></a><p><a href=https://towardsdatascience.com/how-to-create-and-train-a-multi-task-transformer-model-18c54a146240 rel=noopener>How to Create and Train a Multi-Task Transformer Model</a></p><a href=#mulitlang><h3 id=mulitlang><span class=hanchor arialabel=Anchor># </span>Mulitlang</h3></a><p><a href=https://www.ruder.io/multi-qa-tutorial/ rel=noopener>Multi-domain Multilingual Question Answering</a>
<a href=https://towardsdatascience.com/going-global-how-to-multi-task-in-multiple-languages-with-the-mt5-transformer-892617cd890c rel=noopener>How to Multi-Task in Multiple Languages with the mT5 Transformer</a></p><p><a href=https://towardsdatascience.com/many-languages-one-deep-learning-model-69201d02dee1 rel=noopener>Many Languages, One Deep Learning Model</a>
<a href=https://github.com/diyiy/ACL2022_Limited_Data_Learning_Tutorial rel=noopener>ACL 2022 Limited Data Learning Tutorial</a>
<a href=https://github.com/allenai/acl2022-zerofewshot-tutorial rel=noopener>ACL 2022 Tutorial: Zero- and Few-Shot NLP with Pretrained Language Models</a></p><hr><a href=#paper><h2 id=paper><span class=hanchor arialabel=Anchor># </span>Paper</h2></a><a href=#datasets><h3 id=datasets><span class=hanchor arialabel=Anchor># </span>Datasets</h3></a><p><a href=https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00447/109285/Quality-at-a-Glance-An-Audit-of-Web-Crawled rel=noopener>Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets</a>
<a href=https://link.springer.com/article/10.1007/s11042-022-13428-4 rel=noopener>Natural language processing: state of the art, current trends and challenges</a></p><a href=#qa><h3 id=qa><span class=hanchor arialabel=Anchor># </span>QA</h3></a><p><a href=https://aclanthology.org/2021.acl-short.79.pdf rel=noopener>Towards More Equitable Question Answering Systems: How Much More Data Do You Need?</a>
<a href=https://arxiv.org/pdf/2212.01933.pdf rel=noopener>Applying Multilingual Models to Question Answering (QA)</a></p><a href=#multitask-1><h3 id=multitask-1><span class=hanchor arialabel=Anchor># </span>Multitask</h3></a><p><a href=https://arxiv.org/abs/2205.06130 rel=noopener>Multi Task Learning For Zero Shot Performance Prediction of Multilingual Models</a>
<a href=https://arxiv.org/abs/1901.11504v1 rel=noopener>Multi-Task Deep Neural Networks for Natural Language Understanding - 30/05/19</a></p><a href=#multilang><h3 id=multilang><span class=hanchor arialabel=Anchor># </span>Multilang</h3></a><p><a href=https://aclanthology.org/2022.acl-long.265.pdf rel=noopener>Towards Afrocentric NLP for African Languages: Where We Are and Where We Can Go</a>
<a href=https://aclanthology.org/2022.acl-long.367.pdf rel=noopener>KinyaBERT: a Morphology-aware Kinyarwanda Language Model</a></p><p><a href=https://aclanthology.org/2022.acl-long.61/ rel=noopener>Expanding Pretrained Models to Thousands More Languages via Lexicon-based Adaptation</a></p><p><a href="https://openreview.net/forum?id=HJeT3yrtDr" rel=noopener>Cross-Lingual Ability of Multilingual BERT: An Empirical Study</a>
<a href=https://aclanthology.org/K19-1004.pdf rel=noopener>Investigating Cross-Lingual Alignment Methods for Contextualized Embeddings</a></p><a href=#zero-shot-learning><h3 id=zero-shot-learning><span class=hanchor arialabel=Anchor># </span>Zero shot learning</h3></a><p><a href=https://aclanthology.org/2022.acl-long.374/ rel=noopener>Multi Task Learning For Zero Shot Performance Prediction of Multilingual Models 2021</a>
<a href=https://aclanthology.org/D19-1575.pdf rel=noopener>Cross-Lingual BERT Transformation for Zero-Shot Dependency Parsing</a>
<a href=https://arxiv.org/abs/2212.09535 rel=noopener>BLOOM+1: Adding Language Support to BLOOM for Zero-Shot Prompting</a></p><hr><a href=#others><h2 id=others><span class=hanchor arialabel=Anchor># </span>Others</h2></a><a href=#multimodal><h3 id=multimodal><span class=hanchor arialabel=Anchor># </span>multimodal</h3></a><p><a href=https://arxiv.org/abs/2212.09553 rel=noopener>Mu2slam - 19/12/22</a>
<a href=https://ieeexplore.ieee.org/document/9577347 rel=noopener>m3p - 02/11/21 - 56cit</a>
<a href=https://aclanthology.org/2021.findings-emnlp.293/ rel=noopener>MURAL - 11/21</a></p><a href=#cool-link><h3 id=cool-link><span class=hanchor arialabel=Anchor># </span>Cool link</h3></a><p><a href=https://www.ruder.io/tag/natural-language-processing/ rel=noopener>https://www.ruder.io/tag/natural-language-processing/</a></p><a href=#archive><h3 id=archive><span class=hanchor arialabel=Anchor># </span>archive</h3></a><p><a href=https://arxiv.org/abs/2101.10368 rel=noopener>Meta-Learning for Effective Multi-task and Multilingual Modelling</a></p></article><hr><div class=page-end><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://quartz.jzhao.xyz/js/graph.afdb02e537635f9a611b53a988e5645b.js></script></div></div><div id=contact_buttons><footer><p>Made by Jacky Zhao using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, ¬© 2023</p><ul><li><a href=/>Home</a></li><li><a href=https://twitter.com/_jzhao>Twitter</a></li><li><a href=https://github.com/jackyzha0>Github</a></li></ul></footer></div></div></body></html>